{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 01:24:16] [setup] RAM Tracking...\n",
      "[codecarbon INFO @ 01:24:16] [setup] CPU Tracking...\n",
      "[codecarbon WARNING @ 01:24:19] No CPU tracking mode found. Falling back on CPU constant mode. \n",
      " Mac OS and ARM processor detected: Please enable PowerMetrics sudo to measure CPU\n",
      "\n",
      "[codecarbon INFO @ 01:24:20] CPU Model on constant consumption mode: Apple M1\n",
      "[codecarbon INFO @ 01:24:20] [setup] GPU Tracking...\n",
      "[codecarbon INFO @ 01:24:20] No GPU found.\n",
      "[codecarbon INFO @ 01:24:20] >>> Tracker's metadata:\n",
      "[codecarbon INFO @ 01:24:20]   Platform system: macOS-10.16-x86_64-i386-64bit\n",
      "[codecarbon INFO @ 01:24:20]   Python version: 3.9.12\n",
      "[codecarbon INFO @ 01:24:20]   CodeCarbon version: 2.8.3\n",
      "[codecarbon INFO @ 01:24:20]   Available RAM : 8.000 GB\n",
      "[codecarbon INFO @ 01:24:20]   CPU count: 8\n",
      "[codecarbon INFO @ 01:24:20]   CPU model: Apple M1\n",
      "[codecarbon INFO @ 01:24:20]   GPU count: None\n",
      "[codecarbon INFO @ 01:24:20]   GPU model: None\n",
      "[codecarbon INFO @ 01:24:24] Saving emissions data to file /Users/lucia/Desktop/classification_methods/2ND DATASET/MLP/emissions.csv\n"
     ]
    }
   ],
   "source": [
    "from codecarbon import EmissionsTracker\n",
    "try:\n",
    "    tracker.stop()  # Intenta detener cualquier instancia previa de codecarbon\n",
    "except:\n",
    "    pass  # Ignora el error si no hay ninguna instancia activa\n",
    "# Iniciar el medidor\n",
    "tracker = EmissionsTracker()\n",
    "tracker.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt # data visualization\n",
    "import seaborn as sns # statistical data visualization\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = '/Users/lucia/.cache/kagglehub/datasets/bhoomikavalani/donateacrycorpusfeaturesdataset/versions/2/donateacry-corpus_features_final.csv'\n",
    "\n",
    "df = pd.read_csv(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extraer_info_mejorada(ruta):\n",
    "    # Extrae con regex el patrón típico del final del nombre del archivo\n",
    "    match = re.search(r'-([\\d.]+)-(m|f)-(\\d+)-', ruta)\n",
    "    if match:\n",
    "        # match.groups() devuelve (edad_raw, genero, edad_clasificada)\n",
    "        edad_raw, genero, edad = match.groups()\n",
    "        return genero, edad\n",
    "    else:\n",
    "        return None, None  # si no encuentra patrón, deja como None\n",
    "\n",
    "df[['Genero', 'Edad_Codigo']] = df['Cry_Audio_File'].apply(lambda x: pd.Series(extraer_info_mejorada(x)))\n",
    "\n",
    "df['Genero'] = df['Genero'].map({'m': 0, 'f': 1})\n",
    "\n",
    "edad_map = {\n",
    "    '04': 1,\n",
    "    '48': 2,\n",
    "    '26': 3,\n",
    "    '72': 4,\n",
    "    '22': 5\n",
    "}\n",
    "\n",
    "df['Edad'] = df['Edad_Codigo'].map(edad_map)\n",
    "\n",
    "df.drop(columns=['Cry_Audio_File', 'Edad_Codigo'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "np.random.seed(10)\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Required magic to display matplotlib plots in notebooks\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Cry_Reason', 'Amplitude_Envelope_Mean', 'RMS_Mean', 'ZCR_Mean',\n",
       "       'STFT_Mean', 'SC_Mean', 'SBAN_Mean', 'SCON_Mean', 'MFCCs13Mean',\n",
       "       'delMFCCs13', 'del2MFCCs13', 'MelSpec', 'MFCCs20', 'MFCCs1', 'MFCCs2',\n",
       "       'MFCCs3', 'MFCCs4', 'MFCCs5', 'MFCCs6', 'MFCCs7', 'MFCCs8', 'MFCCs9',\n",
       "       'MFCCs10', 'MFCCs11', 'MFCCs12', 'MFCCs13', 'Genero', 'Edad'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_names = df.columns\n",
    "\n",
    "col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['Cry_Reason'], axis=1)\n",
    "\n",
    "y = df['Cry_Reason']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(X_train, columns=[cols])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.DataFrame(X_test, columns=[cols])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODELO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an MLPClassifier model\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(64, 32),\n",
    "                    max_iter=1000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Train the model on the training data\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = mlp.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.40      0.50         5\n",
      "           1       0.00      0.00      0.00         1\n",
      "           2       0.00      0.00      0.00         1\n",
      "           3       0.90      0.90      0.90        79\n",
      "           4       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.79        92\n",
      "   macro avg       0.31      0.26      0.28        92\n",
      "weighted avg       0.81      0.79      0.80        92\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate a classification report\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(f\"Classification Report: {class_report}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CV para encontrar los mejores parámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(64,), learning_rate=constant, solver=sgd; total time=   0.2s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(64,), learning_rate=constant, solver=sgd; total time=   0.2s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(64,), learning_rate=constant, solver=sgd; total time=   0.2s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(64,), learning_rate=constant, solver=sgd; total time=   0.2s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(64,), learning_rate=constant, solver=sgd; total time=   0.2s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(64,), learning_rate=constant, solver=adam; total time=   1.1s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(64,), learning_rate=constant, solver=adam; total time=   1.1s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(64,), learning_rate=constant, solver=adam; total time=   1.1s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(64,), learning_rate=constant, solver=adam; total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(64,), learning_rate=constant, solver=adam; total time=   1.2s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(64,), learning_rate=adaptive, solver=sgd; total time=   0.2s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(64,), learning_rate=adaptive, solver=sgd; total time=   0.2s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(64,), learning_rate=adaptive, solver=sgd; total time=   0.2s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(64,), learning_rate=adaptive, solver=sgd; total time=   0.2s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(64,), learning_rate=adaptive, solver=adam; total time=   1.2s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(64,), learning_rate=adaptive, solver=sgd; total time=   0.2s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(64,), learning_rate=adaptive, solver=adam; total time=   1.1s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(64,), learning_rate=adaptive, solver=adam; total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(64, 32), learning_rate=constant, solver=sgd; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(64, 32), learning_rate=constant, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(64,), learning_rate=adaptive, solver=adam; total time=   1.2s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(64,), learning_rate=adaptive, solver=adam; total time=   1.2s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(64, 32), learning_rate=constant, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(64, 32), learning_rate=constant, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(64, 32), learning_rate=constant, solver=sgd; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(64, 32), learning_rate=constant, solver=adam; total time=   1.9s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(64, 32), learning_rate=constant, solver=adam; total time=   1.8s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(64, 32), learning_rate=constant, solver=adam; total time=   1.9s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(64, 32), learning_rate=constant, solver=adam; total time=   1.8s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(64, 32), learning_rate=constant, solver=adam; total time=   1.9s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(64, 32), learning_rate=adaptive, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(64, 32), learning_rate=adaptive, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(64, 32), learning_rate=adaptive, solver=sgd; total time=   0.5s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(64, 32), learning_rate=adaptive, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(64, 32), learning_rate=adaptive, solver=adam; total time=   1.7s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(64, 32), learning_rate=adaptive, solver=sgd; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(64, 32), learning_rate=adaptive, solver=adam; total time=   1.8s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(64, 32), learning_rate=adaptive, solver=adam; total time=   1.8s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(128, 64), learning_rate=constant, solver=sgd; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(64, 32), learning_rate=adaptive, solver=adam; total time=   1.8s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(64, 32), learning_rate=adaptive, solver=adam; total time=   1.8s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(128, 64), learning_rate=constant, solver=sgd; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(128, 64), learning_rate=constant, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(128, 64), learning_rate=constant, solver=sgd; total time=   0.5s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(128, 64), learning_rate=constant, solver=sgd; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(128, 64), learning_rate=constant, solver=adam; total time=   2.7s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(128, 64), learning_rate=constant, solver=adam; total time=   3.0s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(128, 64), learning_rate=constant, solver=adam; total time=   3.3s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(128, 64), learning_rate=constant, solver=adam; total time=   3.3s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(128, 64), learning_rate=constant, solver=adam; total time=   3.3s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(128, 64), learning_rate=adaptive, solver=sgd; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(128, 64), learning_rate=adaptive, solver=sgd; total time=   0.7s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(128, 64), learning_rate=adaptive, solver=sgd; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 01:24:39] Energy consumed for RAM : 0.000013 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 01:24:39] Energy consumed for all CPUs : 0.000021 kWh. Total CPU Power : 5.0 W\n",
      "[codecarbon INFO @ 01:24:39] 0.000033 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(128, 64), learning_rate=adaptive, solver=sgd; total time=   0.7s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(128, 64), learning_rate=adaptive, solver=adam; total time=   2.8s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(128, 64), learning_rate=adaptive, solver=adam; total time=   3.4s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(128, 64), learning_rate=adaptive, solver=sgd; total time=   0.9s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(128, 64), learning_rate=adaptive, solver=adam; total time=   3.3s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 50, 25), learning_rate=constant, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 50, 25), learning_rate=constant, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(128, 64), learning_rate=adaptive, solver=adam; total time=   3.0s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 50, 25), learning_rate=constant, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 50, 25), learning_rate=constant, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 50, 25), learning_rate=constant, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(128, 64), learning_rate=adaptive, solver=adam; total time=   3.4s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 50, 25), learning_rate=constant, solver=adam; total time=   2.4s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 50, 25), learning_rate=constant, solver=adam; total time=   2.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 50, 25), learning_rate=constant, solver=adam; total time=   3.1s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 50, 25), learning_rate=constant, solver=adam; total time=   3.0s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 50, 25), learning_rate=constant, solver=adam; total time=   2.8s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, solver=sgd; total time=   0.5s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, solver=sgd; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, solver=sgd; total time=   0.5s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, solver=sgd; total time=   0.5s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, solver=sgd; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, solver=adam; total time=   2.3s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, solver=adam; total time=   1.9s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, solver=adam; total time=   2.7s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(64,), learning_rate=constant, solver=sgd; total time=   0.1s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(64,), learning_rate=constant, solver=sgd; total time=   0.1s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, solver=adam; total time=   3.3s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(64,), learning_rate=constant, solver=adam; total time=   1.2s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(64,), learning_rate=constant, solver=adam; total time=   1.1s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(64,), learning_rate=constant, solver=sgd; total time=   0.2s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(64,), learning_rate=constant, solver=sgd; total time=   0.1s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(64,), learning_rate=constant, solver=sgd; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, solver=adam; total time=   2.8s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(64,), learning_rate=constant, solver=adam; total time=   1.1s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(64,), learning_rate=constant, solver=adam; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(64,), learning_rate=adaptive, solver=sgd; total time=   0.2s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(64,), learning_rate=adaptive, solver=sgd; total time=   0.2s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(64,), learning_rate=constant, solver=adam; total time=   1.3s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(64,), learning_rate=adaptive, solver=sgd; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(64,), learning_rate=adaptive, solver=sgd; total time=   0.2s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(64,), learning_rate=adaptive, solver=sgd; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(64,), learning_rate=adaptive, solver=adam; total time=   1.2s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(64,), learning_rate=adaptive, solver=adam; total time=   1.3s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(64,), learning_rate=adaptive, solver=adam; total time=   1.1s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(64,), learning_rate=adaptive, solver=adam; total time=   1.1s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(64,), learning_rate=adaptive, solver=adam; total time=   1.2s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(64, 32), learning_rate=constant, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(64, 32), learning_rate=constant, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(64, 32), learning_rate=constant, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(64, 32), learning_rate=constant, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(64, 32), learning_rate=constant, solver=sgd; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(64, 32), learning_rate=constant, solver=adam; total time=   1.7s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(64, 32), learning_rate=constant, solver=adam; total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(64, 32), learning_rate=constant, solver=adam; total time=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(64, 32), learning_rate=constant, solver=adam; total time=   1.8s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(64, 32), learning_rate=constant, solver=adam; total time=   1.9s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(64, 32), learning_rate=adaptive, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(64, 32), learning_rate=adaptive, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(64, 32), learning_rate=adaptive, solver=adam; total time=   1.8s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(64, 32), learning_rate=adaptive, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(64, 32), learning_rate=adaptive, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(64, 32), learning_rate=adaptive, solver=adam; total time=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(64, 32), learning_rate=adaptive, solver=adam; total time=   1.9s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(64, 32), learning_rate=adaptive, solver=sgd; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(64, 32), learning_rate=adaptive, solver=adam; total time=   1.8s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(128, 64), learning_rate=constant, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(64, 32), learning_rate=adaptive, solver=adam; total time=   1.8s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(128, 64), learning_rate=constant, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(128, 64), learning_rate=constant, solver=sgd; total time=   0.5s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(128, 64), learning_rate=constant, solver=sgd; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(128, 64), learning_rate=constant, solver=sgd; total time=   0.5s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(128, 64), learning_rate=constant, solver=adam; total time=   2.5s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(128, 64), learning_rate=constant, solver=adam; total time=   2.9s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(128, 64), learning_rate=constant, solver=adam; total time=   3.0s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(128, 64), learning_rate=constant, solver=adam; total time=   3.0s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(128, 64), learning_rate=constant, solver=adam; total time=   3.0s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(128, 64), learning_rate=adaptive, solver=sgd; total time=   0.7s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(128, 64), learning_rate=adaptive, solver=sgd; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(128, 64), learning_rate=adaptive, solver=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(128, 64), learning_rate=adaptive, solver=adam; total time=   2.3s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(128, 64), learning_rate=adaptive, solver=adam; total time=   3.0s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(128, 64), learning_rate=adaptive, solver=sgd; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(128, 64), learning_rate=adaptive, solver=adam; total time=   3.2s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(128, 64), learning_rate=adaptive, solver=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50, 25), learning_rate=constant, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50, 25), learning_rate=constant, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(128, 64), learning_rate=adaptive, solver=adam; total time=   3.0s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50, 25), learning_rate=constant, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(128, 64), learning_rate=adaptive, solver=adam; total time=   2.8s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50, 25), learning_rate=constant, solver=adam; total time=   2.0s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50, 25), learning_rate=constant, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50, 25), learning_rate=constant, solver=sgd; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 01:24:54] Energy consumed for RAM : 0.000025 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 01:24:54] Energy consumed for all CPUs : 0.000042 kWh. Total CPU Power : 5.0 W\n",
      "[codecarbon INFO @ 01:24:54] 0.000067 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50, 25), learning_rate=constant, solver=adam; total time=   2.7s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50, 25), learning_rate=constant, solver=adam; total time=   2.7s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50, 25), learning_rate=constant, solver=adam; total time=   2.7s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50, 25), learning_rate=constant, solver=adam; total time=   3.0s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, solver=sgd; total time=   0.5s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, solver=sgd; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, solver=adam; total time=   2.0s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, solver=sgd; total time=   0.5s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, solver=sgd; total time=   0.5s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, solver=sgd; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, solver=adam; total time=   2.7s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, solver=adam; total time=   2.7s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, solver=adam; total time=   2.7s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(64,), learning_rate=constant, solver=sgd; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(64,), learning_rate=constant, solver=adam; total time=   1.1s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(64,), learning_rate=constant, solver=sgd; total time=   0.1s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(64,), learning_rate=constant, solver=sgd; total time=   0.2s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(64,), learning_rate=constant, solver=sgd; total time=   0.2s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(64,), learning_rate=constant, solver=sgd; total time=   0.1s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(64,), learning_rate=constant, solver=adam; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(64,), learning_rate=constant, solver=adam; total time=   1.2s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(64,), learning_rate=constant, solver=adam; total time=   1.2s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(64,), learning_rate=adaptive, solver=sgd; total time=   0.2s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, solver=adam; total time=   3.0s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(64,), learning_rate=adaptive, solver=sgd; total time=   0.2s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(64,), learning_rate=constant, solver=adam; total time=   1.2s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(64,), learning_rate=adaptive, solver=sgd; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(64,), learning_rate=adaptive, solver=sgd; total time=   0.2s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(64,), learning_rate=adaptive, solver=sgd; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(64,), learning_rate=adaptive, solver=adam; total time=   1.2s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(64,), learning_rate=adaptive, solver=adam; total time=   1.1s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(64,), learning_rate=adaptive, solver=adam; total time=   1.3s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(64,), learning_rate=adaptive, solver=adam; total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(64,), learning_rate=adaptive, solver=adam; total time=   1.2s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(64, 32), learning_rate=constant, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(64, 32), learning_rate=constant, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(64, 32), learning_rate=constant, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(64, 32), learning_rate=constant, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(64, 32), learning_rate=constant, solver=sgd; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(64, 32), learning_rate=constant, solver=adam; total time=   1.8s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(64, 32), learning_rate=constant, solver=adam; total time=   1.7s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(64, 32), learning_rate=constant, solver=adam; total time=   1.8s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(64, 32), learning_rate=constant, solver=adam; total time=   2.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(64, 32), learning_rate=constant, solver=adam; total time=   1.8s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(64, 32), learning_rate=adaptive, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(64, 32), learning_rate=adaptive, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(64, 32), learning_rate=adaptive, solver=sgd; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(64, 32), learning_rate=adaptive, solver=adam; total time=   1.7s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(64, 32), learning_rate=adaptive, solver=adam; total time=   1.8s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(64, 32), learning_rate=adaptive, solver=adam; total time=   1.9s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(64, 32), learning_rate=adaptive, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(64, 32), learning_rate=adaptive, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(128, 64), learning_rate=constant, solver=sgd; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(64, 32), learning_rate=adaptive, solver=adam; total time=   1.8s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(64, 32), learning_rate=adaptive, solver=adam; total time=   1.7s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(128, 64), learning_rate=constant, solver=sgd; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(128, 64), learning_rate=constant, solver=sgd; total time=   0.5s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(128, 64), learning_rate=constant, solver=sgd; total time=   0.5s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(128, 64), learning_rate=constant, solver=sgd; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(128, 64), learning_rate=constant, solver=adam; total time=   2.6s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(128, 64), learning_rate=constant, solver=adam; total time=   2.9s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(128, 64), learning_rate=constant, solver=adam; total time=   3.0s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(128, 64), learning_rate=constant, solver=adam; total time=   3.0s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(128, 64), learning_rate=constant, solver=adam; total time=   3.1s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(128, 64), learning_rate=adaptive, solver=sgd; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(128, 64), learning_rate=adaptive, solver=sgd; total time=   0.7s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(128, 64), learning_rate=adaptive, solver=sgd; total time=   0.7s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(128, 64), learning_rate=adaptive, solver=sgd; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(128, 64), learning_rate=adaptive, solver=adam; total time=   3.0s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(128, 64), learning_rate=adaptive, solver=sgd; total time=   0.7s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(128, 64), learning_rate=adaptive, solver=adam; total time=   3.1s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(128, 64), learning_rate=adaptive, solver=adam; total time=   2.7s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50, 25), learning_rate=constant, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50, 25), learning_rate=constant, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(128, 64), learning_rate=adaptive, solver=adam; total time=   2.9s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50, 25), learning_rate=constant, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(128, 64), learning_rate=adaptive, solver=adam; total time=   3.3s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50, 25), learning_rate=constant, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50, 25), learning_rate=constant, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50, 25), learning_rate=constant, solver=adam; total time=   2.4s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50, 25), learning_rate=constant, solver=adam; total time=   2.8s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50, 25), learning_rate=constant, solver=adam; total time=   2.6s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50, 25), learning_rate=constant, solver=adam; total time=   2.7s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50, 25), learning_rate=constant, solver=adam; total time=   2.8s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, solver=sgd; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, solver=sgd; total time=   0.5s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, solver=sgd; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, solver=sgd; total time=   0.5s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, solver=adam; total time=   2.4s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, solver=sgd; total time=   0.5s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, solver=adam; total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 01:25:09] Energy consumed for RAM : 0.000037 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 01:25:09] Energy consumed for all CPUs : 0.000062 kWh. Total CPU Power : 5.0 W\n",
      "[codecarbon INFO @ 01:25:09] 0.000100 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, solver=adam; total time=   2.8s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(64,), learning_rate=constant, solver=sgd; total time=   0.2s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(64,), learning_rate=constant, solver=sgd; total time=   0.2s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(64,), learning_rate=constant, solver=adam; total time=   1.3s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, solver=adam; total time=   2.9s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(64,), learning_rate=constant, solver=sgd; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(64,), learning_rate=constant, solver=sgd; total time=   0.2s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(64,), learning_rate=constant, solver=sgd; total time=   0.2s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(64,), learning_rate=constant, solver=adam; total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(64,), learning_rate=constant, solver=adam; total time=   1.3s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(64,), learning_rate=constant, solver=adam; total time=   1.3s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, solver=adam; total time=   2.7s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(64,), learning_rate=adaptive, solver=sgd; total time=   0.2s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(64,), learning_rate=constant, solver=adam; total time=   1.4s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(64,), learning_rate=adaptive, solver=sgd; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(64,), learning_rate=adaptive, solver=sgd; total time=   0.2s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(64,), learning_rate=adaptive, solver=sgd; total time=   0.2s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(64,), learning_rate=adaptive, solver=sgd; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(64,), learning_rate=adaptive, solver=adam; total time=   1.3s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(64,), learning_rate=adaptive, solver=adam; total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(64,), learning_rate=adaptive, solver=adam; total time=   1.4s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(64,), learning_rate=adaptive, solver=adam; total time=   1.4s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(64,), learning_rate=adaptive, solver=adam; total time=   1.3s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(64, 32), learning_rate=constant, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(64, 32), learning_rate=constant, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(64, 32), learning_rate=constant, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(64, 32), learning_rate=constant, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(64, 32), learning_rate=constant, solver=sgd; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(64, 32), learning_rate=constant, solver=adam; total time=   2.0s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(64, 32), learning_rate=constant, solver=adam; total time=   2.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(64, 32), learning_rate=constant, solver=adam; total time=   2.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(64, 32), learning_rate=constant, solver=adam; total time=   2.2s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(64, 32), learning_rate=adaptive, solver=sgd; total time=   0.5s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(64, 32), learning_rate=constant, solver=adam; total time=   2.1s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(64, 32), learning_rate=adaptive, solver=sgd; total time=   0.5s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(64, 32), learning_rate=adaptive, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(64, 32), learning_rate=adaptive, solver=adam; total time=   2.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(64, 32), learning_rate=adaptive, solver=sgd; total time=   0.6s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(64, 32), learning_rate=adaptive, solver=adam; total time=   2.0s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(64, 32), learning_rate=adaptive, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(128, 64), learning_rate=constant, solver=adam; total time=   0.1s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(64, 32), learning_rate=adaptive, solver=adam; total time=   2.1s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(128, 64), learning_rate=constant, solver=sgd; total time=   0.1s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(128, 64), learning_rate=constant, solver=sgd; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(128, 64), learning_rate=constant, solver=sgd; total time=   0.1s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(128, 64), learning_rate=constant, solver=sgd; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(64, 32), learning_rate=adaptive, solver=adam; total time=   2.1s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(64, 32), learning_rate=adaptive, solver=adam; total time=   2.2s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(128, 64), learning_rate=constant, solver=sgd; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(128, 64), learning_rate=constant, solver=adam; total time=   4.0s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(128, 64), learning_rate=adaptive, solver=adam; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(128, 64), learning_rate=constant, solver=adam; total time=   4.2s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(128, 64), learning_rate=constant, solver=adam; total time=   4.2s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(128, 64), learning_rate=constant, solver=adam; total time=   4.3s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(128, 64), learning_rate=adaptive, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(128, 64), learning_rate=adaptive, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(128, 64), learning_rate=adaptive, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(128, 64), learning_rate=adaptive, solver=adam; total time=   4.2s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(128, 64), learning_rate=adaptive, solver=sgd; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(128, 64), learning_rate=adaptive, solver=adam; total time=   4.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(128, 64), learning_rate=adaptive, solver=adam; total time=   4.3s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(128, 64), learning_rate=adaptive, solver=sgd; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(128, 64), learning_rate=adaptive, solver=adam; total time=   4.2s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 50, 25), learning_rate=constant, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 50, 25), learning_rate=constant, solver=sgd; total time=   0.2s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 50, 25), learning_rate=constant, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 50, 25), learning_rate=constant, solver=sgd; total time=   0.2s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 50, 25), learning_rate=constant, solver=sgd; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 50, 25), learning_rate=constant, solver=adam; total time=   3.6s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 50, 25), learning_rate=constant, solver=adam; total time=   3.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 50, 25), learning_rate=constant, solver=adam; total time=   3.8s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 50, 25), learning_rate=constant, solver=adam; total time=   3.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 50, 25), learning_rate=constant, solver=adam; total time=   3.9s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, solver=sgd; total time=   0.5s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, solver=sgd; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, solver=adam; total time=   3.7s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, solver=sgd; total time=   0.5s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, solver=sgd; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, solver=adam; total time=   3.9s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, solver=adam; total time=   3.8s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(64,), learning_rate=constant, solver=sgd; total time=   0.2s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(64,), learning_rate=constant, solver=sgd; total time=   0.2s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(64,), learning_rate=constant, solver=sgd; total time=   0.1s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(64,), learning_rate=constant, solver=sgd; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 01:25:24] Energy consumed for RAM : 0.000050 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 01:25:24] Energy consumed for all CPUs : 0.000083 kWh. Total CPU Power : 5.0 W\n",
      "[codecarbon INFO @ 01:25:24] 0.000133 kWh of electricity used since the beginning.\n",
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(64,), learning_rate=constant, solver=sgd; total time=   0.2s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(64,), learning_rate=constant, solver=adam; total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(64,), learning_rate=constant, solver=adam; total time=   1.3s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(64,), learning_rate=constant, solver=adam; total time=   1.5s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(64,), learning_rate=constant, solver=adam; total time=   1.3s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(64,), learning_rate=constant, solver=adam; total time=   1.4s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(64,), learning_rate=adaptive, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(64,), learning_rate=adaptive, solver=sgd; total time=   0.5s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(64,), learning_rate=adaptive, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(64,), learning_rate=adaptive, solver=adam; total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(64,), learning_rate=adaptive, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(64,), learning_rate=adaptive, solver=adam; total time=   1.9s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, solver=adam; total time=   4.2s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(64,), learning_rate=adaptive, solver=adam; total time=   1.7s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(64,), learning_rate=adaptive, solver=sgd; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, solver=adam; total time=   4.2s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(64,), learning_rate=adaptive, solver=adam; total time=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(64,), learning_rate=adaptive, solver=adam; total time=   2.0s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(64, 32), learning_rate=constant, solver=sgd; total time=   0.5s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(64, 32), learning_rate=constant, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(64, 32), learning_rate=constant, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(64, 32), learning_rate=constant, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(64, 32), learning_rate=constant, solver=sgd; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(64, 32), learning_rate=constant, solver=adam; total time=   2.2s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(64, 32), learning_rate=constant, solver=adam; total time=   2.3s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(64, 32), learning_rate=constant, solver=adam; total time=   2.5s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(64, 32), learning_rate=constant, solver=adam; total time=   2.3s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(64, 32), learning_rate=constant, solver=adam; total time=   2.3s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(64, 32), learning_rate=adaptive, solver=sgd; total time=   0.5s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(64, 32), learning_rate=adaptive, solver=sgd; total time=   0.6s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(64, 32), learning_rate=adaptive, solver=sgd; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(64, 32), learning_rate=adaptive, solver=adam; total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(64, 32), learning_rate=adaptive, solver=adam; total time=   2.3s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(64, 32), learning_rate=adaptive, solver=sgd; total time=   0.5s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(64, 32), learning_rate=adaptive, solver=adam; total time=   2.5s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(64, 32), learning_rate=adaptive, solver=sgd; total time=   0.9s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(128, 64), learning_rate=constant, solver=adam; total time=   0.1s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(128, 64), learning_rate=constant, solver=sgd; total time=   0.1s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(128, 64), learning_rate=constant, solver=sgd; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(128, 64), learning_rate=constant, solver=sgd; total time=   0.1s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(128, 64), learning_rate=constant, solver=sgd; total time=   0.1s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(128, 64), learning_rate=constant, solver=sgd; total time=   0.9s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(64, 32), learning_rate=adaptive, solver=adam; total time=   2.6s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(64, 32), learning_rate=adaptive, solver=adam; total time=   2.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(128, 64), learning_rate=constant, solver=adam; total time=   4.8s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(128, 64), learning_rate=constant, solver=adam; total time=   5.0s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(128, 64), learning_rate=adaptive, solver=adam; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(128, 64), learning_rate=constant, solver=adam; total time=   4.8s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(128, 64), learning_rate=constant, solver=adam; total time=   5.0s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(128, 64), learning_rate=adaptive, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(128, 64), learning_rate=adaptive, solver=sgd; total time=   0.6s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(128, 64), learning_rate=adaptive, solver=adam; total time=   4.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(128, 64), learning_rate=adaptive, solver=sgd; total time=   0.5s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(128, 64), learning_rate=adaptive, solver=sgd; total time=   0.5s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(128, 64), learning_rate=adaptive, solver=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(128, 64), learning_rate=adaptive, solver=adam; total time=   4.6s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(128, 64), learning_rate=adaptive, solver=adam; total time=   4.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50, 25), learning_rate=constant, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(128, 64), learning_rate=adaptive, solver=adam; total time=   4.9s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50, 25), learning_rate=constant, solver=sgd; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50, 25), learning_rate=constant, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50, 25), learning_rate=constant, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50, 25), learning_rate=constant, solver=sgd; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50, 25), learning_rate=constant, solver=adam; total time=   4.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[codecarbon INFO @ 01:25:39] Energy consumed for RAM : 0.000062 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 01:25:39] Energy consumed for all CPUs : 0.000104 kWh. Total CPU Power : 5.0 W\n",
      "[codecarbon INFO @ 01:25:39] 0.000167 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50, 25), learning_rate=constant, solver=adam; total time=   4.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50, 25), learning_rate=constant, solver=adam; total time=   4.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50, 25), learning_rate=constant, solver=adam; total time=   4.5s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, solver=sgd; total time=   0.5s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50, 25), learning_rate=constant, solver=adam; total time=   4.4s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, solver=sgd; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, solver=sgd; total time=   0.6s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, solver=sgd; total time=   0.5s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, solver=sgd; total time=   0.5s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, solver=adam; total time=   4.4s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, solver=adam; total time=   4.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, solver=adam; total time=   4.3s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(64,), learning_rate=constant, solver=sgd; total time=   0.2s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(64,), learning_rate=constant, solver=sgd; total time=   0.2s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(64,), learning_rate=constant, solver=sgd; total time=   0.2s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(64,), learning_rate=constant, solver=sgd; total time=   0.2s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(64,), learning_rate=constant, solver=sgd; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(64,), learning_rate=constant, solver=adam; total time=   1.6s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(64,), learning_rate=constant, solver=adam; total time=   1.5s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(64,), learning_rate=constant, solver=adam; total time=   1.6s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(64,), learning_rate=constant, solver=adam; total time=   1.6s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(64,), learning_rate=constant, solver=adam; total time=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(64,), learning_rate=adaptive, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(64,), learning_rate=adaptive, solver=sgd; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(64,), learning_rate=adaptive, solver=adam; total time=   1.5s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(64,), learning_rate=adaptive, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, solver=adam; total time=   4.3s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, solver=adam; total time=   4.6s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(64,), learning_rate=adaptive, solver=adam; total time=   1.5s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(64,), learning_rate=adaptive, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(64,), learning_rate=adaptive, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(64,), learning_rate=adaptive, solver=adam; total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(64,), learning_rate=adaptive, solver=adam; total time=   1.8s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(64,), learning_rate=adaptive, solver=adam; total time=   1.7s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(64, 32), learning_rate=constant, solver=sgd; total time=   0.6s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(64, 32), learning_rate=constant, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(64, 32), learning_rate=constant, solver=sgd; total time=   0.5s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(64, 32), learning_rate=constant, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(64, 32), learning_rate=constant, solver=sgd; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(64, 32), learning_rate=constant, solver=adam; total time=   2.5s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(64, 32), learning_rate=constant, solver=adam; total time=   2.5s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(64, 32), learning_rate=constant, solver=adam; total time=   2.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(64, 32), learning_rate=constant, solver=adam; total time=   2.5s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(64, 32), learning_rate=constant, solver=adam; total time=   2.5s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(64, 32), learning_rate=adaptive, solver=sgd; total time=   0.5s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(64, 32), learning_rate=adaptive, solver=adam; total time=   2.2s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(64, 32), learning_rate=adaptive, solver=sgd; total time=   0.5s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(64, 32), learning_rate=adaptive, solver=sgd; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(64, 32), learning_rate=adaptive, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(64, 32), learning_rate=adaptive, solver=adam; total time=   2.3s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(64, 32), learning_rate=adaptive, solver=sgd; total time=   0.6s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(64, 32), learning_rate=adaptive, solver=adam; total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(128, 64), learning_rate=constant, solver=adam; total time=   0.1s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(128, 64), learning_rate=constant, solver=sgd; total time=   0.1s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(128, 64), learning_rate=constant, solver=sgd; total time=   0.1s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(128, 64), learning_rate=constant, solver=sgd; total time=   0.1s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(128, 64), learning_rate=constant, solver=sgd; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(64, 32), learning_rate=adaptive, solver=adam; total time=   2.2s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(128, 64), learning_rate=constant, solver=sgd; total time=   0.7s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(64, 32), learning_rate=adaptive, solver=adam; total time=   2.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(128, 64), learning_rate=constant, solver=adam; total time=   4.2s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(128, 64), learning_rate=constant, solver=adam; total time=   4.1s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(128, 64), learning_rate=adaptive, solver=adam; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(128, 64), learning_rate=constant, solver=adam; total time=   4.2s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(128, 64), learning_rate=constant, solver=adam; total time=   4.2s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(128, 64), learning_rate=adaptive, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(128, 64), learning_rate=adaptive, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(128, 64), learning_rate=adaptive, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(128, 64), learning_rate=adaptive, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(128, 64), learning_rate=adaptive, solver=adam; total time=   4.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(128, 64), learning_rate=adaptive, solver=adam; total time=   4.1s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(128, 64), learning_rate=adaptive, solver=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(128, 64), learning_rate=adaptive, solver=adam; total time=   4.2s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(128, 64), learning_rate=adaptive, solver=adam; total time=   4.2s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50, 25), learning_rate=constant, solver=sgd; total time=   0.2s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50, 25), learning_rate=constant, solver=sgd; total time=   0.2s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50, 25), learning_rate=constant, solver=sgd; total time=   0.2s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50, 25), learning_rate=constant, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50, 25), learning_rate=constant, solver=sgd; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 01:25:54] Energy consumed for RAM : 0.000075 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 01:25:54] Energy consumed for all CPUs : 0.000125 kWh. Total CPU Power : 5.0 W\n",
      "[codecarbon INFO @ 01:25:54] 0.000200 kWh of electricity used since the beginning.\n",
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50, 25), learning_rate=constant, solver=adam; total time=   3.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50, 25), learning_rate=constant, solver=adam; total time=   3.9s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50, 25), learning_rate=constant, solver=adam; total time=   3.8s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50, 25), learning_rate=constant, solver=adam; total time=   3.8s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50, 25), learning_rate=constant, solver=adam; total time=   3.9s[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, solver=sgd; total time=   0.5s\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, solver=adam; total time=   3.7s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(64,), learning_rate=constant, solver=adam; total time=   0.1s\n",
      "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(64,), learning_rate=constant, solver=adam; total time=   0.1s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, solver=adam; total time=   3.7s\n",
      "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(64,), learning_rate=constant, solver=adam; total time=   0.2s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, solver=sgd; total time=   0.5s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, solver=sgd; total time=   0.5s\n",
      "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(64,), learning_rate=constant, solver=adam; total time=   0.1s\n",
      "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(64,), learning_rate=constant, solver=sgd; total time=   0.1s\n",
      "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(64,), learning_rate=constant, solver=adam; total time=   0.1s\n",
      "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(64,), learning_rate=constant, solver=sgd; total time=   0.1s\n",
      "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(64,), learning_rate=constant, solver=sgd; total time=   0.1s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, solver=adam; total time=   3.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(64,), learning_rate=constant, solver=sgd; total time=   0.1s\n",
      "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(64,), learning_rate=constant, solver=sgd; total time=   0.1s\n",
      "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(64,), learning_rate=adaptive, solver=adam; total time=   0.1s\n",
      "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(64,), learning_rate=adaptive, solver=adam; total time=   0.1s\n",
      "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(64,), learning_rate=adaptive, solver=adam; total time=   0.2s\n",
      "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(64,), learning_rate=adaptive, solver=adam; total time=   0.2s\n",
      "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(64,), learning_rate=adaptive, solver=adam; total time=   0.1s\n",
      "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(64,), learning_rate=adaptive, solver=sgd; total time=   0.2s\n",
      "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(64,), learning_rate=adaptive, solver=sgd; total time=   0.2s\n",
      "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(64, 32), learning_rate=constant, solver=adam; total time=   0.1s\n",
      "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(64,), learning_rate=adaptive, solver=sgd; total time=   0.2s\n",
      "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(64,), learning_rate=adaptive, solver=sgd; total time=   0.2s\n",
      "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(64, 32), learning_rate=constant, solver=adam; total time=   0.1s\n",
      "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(64, 32), learning_rate=constant, solver=adam; total time=   0.1s\n",
      "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(64,), learning_rate=adaptive, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(64, 32), learning_rate=constant, solver=adam; total time=   0.1s\n",
      "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(64, 32), learning_rate=constant, solver=adam; total time=   0.2s\n",
      "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(64, 32), learning_rate=constant, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(64, 32), learning_rate=constant, solver=sgd; total time=   0.2s\n",
      "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(64, 32), learning_rate=adaptive, solver=adam; total time=   0.1s\n",
      "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(64, 32), learning_rate=constant, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(64, 32), learning_rate=constant, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(64, 32), learning_rate=constant, solver=sgd; total time=   0.2s\n",
      "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(64, 32), learning_rate=adaptive, solver=adam; total time=   0.1s\n",
      "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(64, 32), learning_rate=adaptive, solver=adam; total time=   0.1s\n",
      "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(64, 32), learning_rate=adaptive, solver=adam; total time=   0.1s\n",
      "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(64, 32), learning_rate=adaptive, solver=adam; total time=   0.2s\n",
      "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(128, 64), learning_rate=constant, solver=adam; total time=   0.1s\n",
      "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(64, 32), learning_rate=adaptive, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(64, 32), learning_rate=adaptive, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(64, 32), learning_rate=adaptive, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(64, 32), learning_rate=adaptive, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(128, 64), learning_rate=constant, solver=adam; total time=   0.2s\n",
      "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(64, 32), learning_rate=adaptive, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(128, 64), learning_rate=constant, solver=adam; total time=   0.1s\n",
      "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(128, 64), learning_rate=constant, solver=adam; total time=   0.2s\n",
      "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(128, 64), learning_rate=constant, solver=adam; total time=   0.3s\n",
      "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(128, 64), learning_rate=adaptive, solver=adam; total time=   0.1s\n",
      "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(128, 64), learning_rate=constant, solver=sgd; total time=   0.2s\n",
      "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(128, 64), learning_rate=constant, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(128, 64), learning_rate=constant, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(128, 64), learning_rate=constant, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(128, 64), learning_rate=adaptive, solver=adam; total time=   0.1s\n",
      "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(128, 64), learning_rate=adaptive, solver=adam; total time=   0.2s\n",
      "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(128, 64), learning_rate=constant, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(128, 64), learning_rate=adaptive, solver=adam; total time=   0.2s\n",
      "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(128, 64), learning_rate=adaptive, solver=adam; total time=   0.3s\n",
      "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(128, 64), learning_rate=adaptive, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(100, 50, 25), learning_rate=constant, solver=adam; total time=   0.3s\n",
      "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(128, 64), learning_rate=adaptive, solver=sgd; total time=   0.5s\n",
      "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(128, 64), learning_rate=adaptive, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(128, 64), learning_rate=adaptive, solver=sgd; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, solver=adam; total time=   3.7s\n",
      "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(128, 64), learning_rate=adaptive, solver=sgd; total time=   0.5s\n",
      "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(100, 50, 25), learning_rate=constant, solver=adam; total time=   0.3s\n",
      "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(100, 50, 25), learning_rate=constant, solver=adam; total time=   0.3s\n",
      "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(100, 50, 25), learning_rate=constant, solver=adam; total time=   0.3s\n",
      "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(100, 50, 25), learning_rate=constant, solver=adam; total time=   0.3s\n",
      "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(100, 50, 25), learning_rate=constant, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(100, 50, 25), learning_rate=constant, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(100, 50, 25), learning_rate=constant, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, solver=adam; total time=   0.3s\n",
      "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(100, 50, 25), learning_rate=constant, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, solver=adam; total time=   3.7s\n",
      "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, solver=adam; total time=   0.3s\n",
      "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(100, 50, 25), learning_rate=constant, solver=sgd; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, solver=adam; total time=   0.3s\n",
      "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, solver=adam; total time=   0.3s\n",
      "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, solver=adam; total time=   0.4s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(64,), learning_rate=constant, solver=adam; total time=   0.1s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(64,), learning_rate=constant, solver=adam; total time=   0.1s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(64,), learning_rate=constant, solver=adam; total time=   0.1s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(64,), learning_rate=constant, solver=adam; total time=   0.1s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(64,), learning_rate=constant, solver=adam; total time=   0.1s\n",
      "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, solver=sgd; total time=   0.6s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(64,), learning_rate=constant, solver=sgd; total time=   0.1s\n",
      "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, solver=sgd; total time=   0.6s\n",
      "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, solver=sgd; total time=   0.5s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(64,), learning_rate=constant, solver=sgd; total time=   0.2s\n",
      "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, solver=sgd; total time=   0.6s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(64,), learning_rate=constant, solver=sgd; total time=   0.1s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(64,), learning_rate=constant, solver=sgd; total time=   0.1s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(64,), learning_rate=constant, solver=sgd; total time=   0.1s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(64,), learning_rate=adaptive, solver=adam; total time=   0.1s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(64,), learning_rate=adaptive, solver=adam; total time=   0.1s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(64,), learning_rate=adaptive, solver=adam; total time=   0.2s\n",
      "[CV] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, solver=sgd; total time=   0.7s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(64,), learning_rate=adaptive, solver=adam; total time=   0.2s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(64,), learning_rate=adaptive, solver=adam; total time=   0.1s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(64,), learning_rate=adaptive, solver=sgd; total time=   0.2s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(64,), learning_rate=adaptive, solver=sgd; total time=   0.2s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(64,), learning_rate=adaptive, solver=sgd; total time=   0.2s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(64, 32), learning_rate=constant, solver=adam; total time=   0.1s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(64, 32), learning_rate=constant, solver=adam; total time=   0.2s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(64, 32), learning_rate=constant, solver=adam; total time=   0.1s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(64,), learning_rate=adaptive, solver=sgd; total time=   0.2s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(64, 32), learning_rate=constant, solver=adam; total time=   0.1s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(64,), learning_rate=adaptive, solver=sgd; total time=   0.2s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(64, 32), learning_rate=constant, solver=adam; total time=   0.2s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(64, 32), learning_rate=constant, solver=sgd; total time=   0.2s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(64, 32), learning_rate=adaptive, solver=adam; total time=   0.1s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(64, 32), learning_rate=adaptive, solver=adam; total time=   0.1s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(64, 32), learning_rate=constant, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(64, 32), learning_rate=constant, solver=sgd; total time=   0.2s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(64, 32), learning_rate=constant, solver=sgd; total time=   0.2s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(64, 32), learning_rate=constant, solver=sgd; total time=   0.2s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(64, 32), learning_rate=adaptive, solver=adam; total time=   0.1s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(128, 64), learning_rate=constant, solver=adam; total time=   0.1s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(64, 32), learning_rate=adaptive, solver=adam; total time=   0.2s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(64, 32), learning_rate=adaptive, solver=adam; total time=   0.2s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(128, 64), learning_rate=constant, solver=adam; total time=   0.1s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(64, 32), learning_rate=adaptive, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(128, 64), learning_rate=constant, solver=adam; total time=   0.2s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(64, 32), learning_rate=adaptive, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(128, 64), learning_rate=constant, solver=adam; total time=   0.2s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(64, 32), learning_rate=adaptive, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(64, 32), learning_rate=adaptive, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(64, 32), learning_rate=adaptive, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(128, 64), learning_rate=adaptive, solver=adam; total time=   0.1s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(128, 64), learning_rate=constant, solver=adam; total time=   0.2s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(128, 64), learning_rate=constant, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(128, 64), learning_rate=constant, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(128, 64), learning_rate=adaptive, solver=adam; total time=   0.1s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(128, 64), learning_rate=constant, solver=sgd; total time=   0.2s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(128, 64), learning_rate=constant, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(128, 64), learning_rate=constant, solver=sgd; total time=   0.2s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(128, 64), learning_rate=adaptive, solver=adam; total time=   0.2s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(128, 64), learning_rate=adaptive, solver=adam; total time=   0.3s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(128, 64), learning_rate=adaptive, solver=adam; total time=   0.2s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(100, 50, 25), learning_rate=constant, solver=adam; total time=   0.3s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(128, 64), learning_rate=adaptive, solver=sgd; total time=   0.5s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(100, 50, 25), learning_rate=constant, solver=adam; total time=   0.3s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(100, 50, 25), learning_rate=constant, solver=adam; total time=   0.3s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(128, 64), learning_rate=adaptive, solver=sgd; total time=   0.5s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(128, 64), learning_rate=adaptive, solver=sgd; total time=   0.5s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(128, 64), learning_rate=adaptive, solver=sgd; total time=   0.5s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(128, 64), learning_rate=adaptive, solver=sgd; total time=   0.5s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(100, 50, 25), learning_rate=constant, solver=adam; total time=   0.3s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(100, 50, 25), learning_rate=constant, solver=adam; total time=   0.3s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, solver=adam; total time=   0.3s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(100, 50, 25), learning_rate=constant, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(100, 50, 25), learning_rate=constant, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(100, 50, 25), learning_rate=constant, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(100, 50, 25), learning_rate=constant, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, solver=adam; total time=   0.2s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(100, 50, 25), learning_rate=constant, solver=sgd; total time=   0.5s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, solver=adam; total time=   0.3s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, solver=adam; total time=   0.3s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, solver=adam; total time=   0.6s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(64,), learning_rate=constant, solver=adam; total time=   0.1s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(64,), learning_rate=constant, solver=adam; total time=   0.2s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(64,), learning_rate=constant, solver=adam; total time=   0.1s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, solver=sgd; total time=   0.5s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(64,), learning_rate=constant, solver=adam; total time=   0.1s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, solver=sgd; total time=   0.6s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(64,), learning_rate=constant, solver=adam; total time=   0.2s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, solver=sgd; total time=   0.6s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(64,), learning_rate=constant, solver=sgd; total time=   0.1s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, solver=sgd; total time=   0.5s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(64,), learning_rate=constant, solver=sgd; total time=   0.1s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(64,), learning_rate=constant, solver=sgd; total time=   0.1s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(64,), learning_rate=constant, solver=sgd; total time=   0.1s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(64,), learning_rate=adaptive, solver=adam; total time=   0.1s\n",
      "[CV] END activation=logistic, alpha=0.001, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, solver=sgd; total time=   0.6s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(64,), learning_rate=constant, solver=sgd; total time=   0.1s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(64,), learning_rate=adaptive, solver=adam; total time=   0.1s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(64,), learning_rate=adaptive, solver=adam; total time=   0.1s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(64,), learning_rate=adaptive, solver=adam; total time=   0.1s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(64,), learning_rate=adaptive, solver=adam; total time=   0.2s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(64,), learning_rate=adaptive, solver=sgd; total time=   0.2s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(64,), learning_rate=adaptive, solver=sgd; total time=   0.2s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(64,), learning_rate=adaptive, solver=sgd; total time=   0.2s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(64,), learning_rate=adaptive, solver=sgd; total time=   0.2s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(64, 32), learning_rate=constant, solver=adam; total time=   0.1s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(64,), learning_rate=adaptive, solver=sgd; total time=   0.2s[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(64, 32), learning_rate=constant, solver=adam; total time=   0.1s\n",
      "\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(64, 32), learning_rate=constant, solver=adam; total time=   0.1s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(64, 32), learning_rate=constant, solver=adam; total time=   0.1s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(64, 32), learning_rate=constant, solver=adam; total time=   0.1s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(64, 32), learning_rate=adaptive, solver=adam; total time=   0.1s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(64, 32), learning_rate=constant, solver=sgd; total time=   0.2s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(64, 32), learning_rate=adaptive, solver=adam; total time=   0.1s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(64, 32), learning_rate=constant, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(64, 32), learning_rate=adaptive, solver=adam; total time=   0.1s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(64, 32), learning_rate=constant, solver=sgd; total time=   0.2s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(64, 32), learning_rate=constant, solver=sgd; total time=   0.2s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(64, 32), learning_rate=adaptive, solver=adam; total time=   0.1s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(64, 32), learning_rate=constant, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(64, 32), learning_rate=adaptive, solver=adam; total time=   0.1s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(128, 64), learning_rate=constant, solver=adam; total time=   0.1s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(128, 64), learning_rate=constant, solver=adam; total time=   0.1s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(64, 32), learning_rate=adaptive, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(64, 32), learning_rate=adaptive, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(64, 32), learning_rate=adaptive, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(64, 32), learning_rate=adaptive, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(64, 32), learning_rate=adaptive, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(128, 64), learning_rate=constant, solver=adam; total time=   0.3s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(128, 64), learning_rate=constant, solver=adam; total time=   0.3s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(128, 64), learning_rate=constant, solver=adam; total time=   0.2s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(128, 64), learning_rate=adaptive, solver=adam; total time=   0.1s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(128, 64), learning_rate=constant, solver=sgd; total time=   0.2s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(128, 64), learning_rate=adaptive, solver=adam; total time=   0.2s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(128, 64), learning_rate=adaptive, solver=adam; total time=   0.1s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(128, 64), learning_rate=constant, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(128, 64), learning_rate=constant, solver=sgd; total time=   0.2s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(128, 64), learning_rate=constant, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(128, 64), learning_rate=constant, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(128, 64), learning_rate=adaptive, solver=adam; total time=   0.3s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(128, 64), learning_rate=adaptive, solver=adam; total time=   0.2s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(100, 50, 25), learning_rate=constant, solver=adam; total time=   0.3s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(100, 50, 25), learning_rate=constant, solver=adam; total time=   0.3s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(100, 50, 25), learning_rate=constant, solver=adam; total time=   0.3s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(128, 64), learning_rate=adaptive, solver=sgd; total time=   0.5s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(128, 64), learning_rate=adaptive, solver=sgd; total time=   0.5s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(128, 64), learning_rate=adaptive, solver=sgd; total time=   0.5s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(128, 64), learning_rate=adaptive, solver=sgd; total time=   0.5s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(128, 64), learning_rate=adaptive, solver=sgd; total time=   0.5s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(100, 50, 25), learning_rate=constant, solver=adam; total time=   0.3s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(100, 50, 25), learning_rate=constant, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, solver=adam; total time=   0.2s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(100, 50, 25), learning_rate=constant, solver=adam; total time=   0.4s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(100, 50, 25), learning_rate=constant, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(100, 50, 25), learning_rate=constant, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(100, 50, 25), learning_rate=constant, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, solver=adam; total time=   0.3s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(100, 50, 25), learning_rate=constant, solver=sgd; total time=   0.5s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, solver=adam; total time=   0.3s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, solver=adam; total time=   0.3s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, solver=adam; total time=   0.3s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, solver=sgd; total time=   0.5s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, solver=sgd; total time=   0.6s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=logistic, alpha=0.01, hidden_layer_sizes=(100, 50, 25), learning_rate=adaptive, solver=sgd; total time=   0.4s\n",
      "Mejores parámetros encontrados:\n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (64,), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "Mejor accuracy en validación cruzada: 0.8301\n",
      "Accuracy en test set: 0.8587\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Definir los parámetros a probar\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(64,), (64, 32), (128, 64), (100, 50, 25)],\n",
    "    'activation': ['relu', 'tanh', 'logistic'],\n",
    "    'solver': ['adam', 'sgd'],\n",
    "    'alpha': [0.0001, 0.001, 0.01],\n",
    "    'learning_rate': ['constant', 'adaptive']\n",
    "}\n",
    "\n",
    "# Crear el modelo base\n",
    "mlp = MLPClassifier(max_iter=1000, random_state=42)\n",
    "\n",
    "# GridSearch con validación cruzada de 5 folds\n",
    "grid_search = GridSearchCV(estimator=mlp,\n",
    "                           param_grid=param_grid,\n",
    "                           scoring='accuracy',\n",
    "                           cv=5,\n",
    "                           n_jobs=-1,     # Usa todos los núcleos disponibles\n",
    "                           verbose=2)\n",
    "\n",
    "# Entrenar\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Resultados\n",
    "print(\"Mejores parámetros encontrados:\")\n",
    "print(grid_search.best_params_)\n",
    "print(f\"Mejor accuracy en validación cruzada: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Evaluar en test\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy en test set: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en test con el modelo final: 0.8587\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Crear el modelo con los mejores parámetros encontrados\n",
    "final_mlp = MLPClassifier(hidden_layer_sizes=(64,),\n",
    "                          activation='relu',\n",
    "                          solver='sgd',\n",
    "                          alpha=0.0001,\n",
    "                          learning_rate='constant',\n",
    "                          max_iter=2000,          # un poco más alto por si no converge\n",
    "                          momentum=0.9,           # mejora con SGD\n",
    "                          random_state=42)\n",
    "\n",
    "# Entrenar el modelo\n",
    "final_mlp.fit(X_train, y_train)\n",
    "\n",
    "# Predecir\n",
    "y_pred = final_mlp.predict(X_test)\n",
    "\n",
    "# Evaluar\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy en test con el modelo final: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:      0.8587\n",
      "Sensibilidad:  0.8587\n",
      "F1 Score:      0.7934\n",
      "AUC (weighted): 0.7268\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# Predicciones\n",
    "y_pred = final_mlp.predict(X_test)\n",
    "y_proba = final_mlp.predict_proba(X_test)\n",
    "\n",
    "# Métricas\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred, average='weighted')     # Sensibilidad ponderada\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "auc = roc_auc_score(y_test, y_proba, multi_class='ovr', average='weighted')\n",
    "\n",
    "# Mostrar resultados\n",
    "print(f\"Accuracy:      {accuracy:.4f}\")\n",
    "print(f\"Sensibilidad:  {recall:.4f}\")\n",
    "print(f\"F1 Score:      {f1:.4f}\")\n",
    "print(f\"AUC (weighted): {auc:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import numpy as np\n",
    "\n",
    "# Asegúrate de tener clases codificadas como números (0, 1, 2, ...)\n",
    "classes = np.unique(y_test)\n",
    "n_classes = len(classes)\n",
    "\n",
    "# Binarizar las etiquetas para multiclase\n",
    "y_test_bin = label_binarize(y_test, classes=classes)\n",
    "y_proba = final_mlp.predict_proba(X_test)\n",
    "\n",
    "# Calcular curva ROC y AUC por clase\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_proba[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i in range(n_classes):\n",
    "    plt.plot(fpr[i], tpr[i], label=f'Clase {classes[i]} (AUC = {roc_auc[i]:.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Azar')\n",
    "plt.xlabel('Tasa de Falsos Positivos')\n",
    "plt.ylabel('Tasa de Verdaderos Positivos')\n",
    "plt.title('Curvas ROC por clase')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Obtener predicciones\n",
    "y_pred = final_mlp.predict(X_test)\n",
    "\n",
    "# Calcular y mostrar la matriz de confusión\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "disp.plot(cmap=plt.cm.Blues, values_format='d')\n",
    "plt.title('Matriz de Confusión')\n",
    "plt.grid(False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try SMOTE for imbalanced classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribución de clases antes del SMOTE: Counter({3: 305, 2: 22, 4: 19, 0: 13, 1: 6})\n",
      "Distribución de clases después del SMOTE: Counter({2: 305, 3: 305, 4: 305, 0: 305, 1: 305})\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1. Separar en train/test (si no lo habías hecho ya)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42,\n",
    "                                                    stratify=y)  # Muy importante: mantener distribución por clase\n",
    "\n",
    "# 2. Aplicar SMOTE solo sobre los datos de entrenamiento\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Verificación\n",
    "from collections import Counter\n",
    "print(\"Distribución de clases antes del SMOTE:\", Counter(y_train))\n",
    "print(\"Distribución de clases después del SMOTE:\", Counter(y_train_smote))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:      0.0870\n",
      "Sensibilidad:  0.0870\n",
      "F1 Score:      0.1206\n",
      "AUC (weighted): 0.5128\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, roc_auc_score\n",
    "\n",
    "mlp_smote = MLPClassifier(hidden_layer_sizes=(64,),\n",
    "                          activation='relu',\n",
    "                          solver='sgd',\n",
    "                          alpha=0.0001,\n",
    "                          learning_rate='constant',\n",
    "                          max_iter=2000,\n",
    "                          momentum=0.9,\n",
    "                          random_state=42)\n",
    "\n",
    "# Entrenar con datos balanceados\n",
    "mlp_smote.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Evaluar con el test original (sin rebalancear)\n",
    "y_pred = mlp_smote.predict(X_test)\n",
    "y_proba = mlp_smote.predict_proba(X_test)\n",
    "\n",
    "# Métricas (ahora weighted)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "auc = roc_auc_score(y_test, y_proba, multi_class='ovr', average='weighted')\n",
    "\n",
    "print(f\"Accuracy:      {accuracy:.4f}\")\n",
    "print(f\"Sensibilidad:  {recall:.4f}\")\n",
    "print(f\"F1 Score:      {f1:.4f}\")\n",
    "print(f\"AUC (weighted): {auc:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP no gestiona bien el desbalance de clases, ni siquiera con oversampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 01:26:06] Energy consumed for RAM : 0.000085 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 01:26:06] Energy consumed for all CPUs : 0.000142 kWh. Total CPU Power : 5.0 W\n",
      "[codecarbon INFO @ 01:26:06] 0.000228 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.6754110766703034e-05"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Detener el medidor y obtener los resultados\n",
    "tracker.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
